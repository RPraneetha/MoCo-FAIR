{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch as torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport os\nimport torchvision\nimport torch.nn as nn\nfrom torch.autograd import Variable as var\nimport logging as log\nimport gc\nimport numpy as np\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nfrom glob import glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CUDA for PyTorch\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\ntorch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Constants\nN = 128 # Batch Size\nT = 0.07 # Temperature\nC = 3 # Number of Channels\nm = 0.9 # momemntum contrast\nK = 4096 # dictionary size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA = '/kaggle/input/imagenetmini-1000/imagenet-mini/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageNet(Dataset):\n    def __init__(self, root_dir, train=False, transform=None):\n\n            self.root_dir = root_dir\n            \n            self.transform = transform\n\n            self.sub_directory = 'train' if train else 'val'\n            \n            path = os.path.join(\n            root_dir, self.sub_directory, \"*\",\"*\")\n            \n            self.imgs = glob(path)\n            \n    def __len__(self):\n        return len(self.imgs)\n    \n    def __getitem__(self,idx):\n        img = Image.open(self.imgs[idx],).convert('RGB')\n        if self.transform is not None:\n            img = self.transform(img);\n\n        return img;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Augmentations\n\ndef get_random_augmentation():\n    return transforms.Compose([\n        transforms.RandomResizedCrop(size=224,scale=(0.2, 1.)),\n        transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n        transforms.RandomHorizontalFlip(),\n        transforms.Grayscale(num_output_channels=C),\n        transforms.ToTensor(),\n        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Load Data\ntransform = get_random_augmentation()\n\ntrain_data = ImageNet(\n    root_dir=DATA, train=True,  transform=transform)\ntest_data = ImageNet(\n    root_dir=DATA, train=False,  transform=transform)\n\ntrain_set = torch.utils.data.DataLoader(\n    train_data, batch_size=N,shuffle=True,num_workers = 4, pin_memory=True, drop_last=True)\ntest_set = torch.utils.data.DataLoader(\n    test_data, batch_size=N,shuffle=False,num_workers = 4,pin_memory=True, drop_last=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Resnet50Model(nn.Module):\n    def __init__(self):\n        super(Resnet50Model, self).__init__()\n\n        model = models.resnet50(pretrained=False)\n        modules = list(model.children())[:-1]\n        self.resnet = nn.Sequential(*modules)\n        self.fc = nn.Sequential(nn.Linear(2048, N), nn.ReLU())\n    \n    def forward(self,x):\n        x = self.resnet(x)\n        x = x.view(x.size(0),-1)\n        x = self.fc(x)\n        \n        return x\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_q = Resnet50Model().cuda()\nencoder_k = Resnet50Model().cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.SGD(encoder_q.parameters(), lr=0.03, momentum=0.9, weight_decay=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cec = nn.CrossEntropyLoss().cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param_q, param_k in zip(encoder_q.parameters(), encoder_k.parameters()):\n            param_k.data.copy_(param_q.data)\n            param_k.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef dequeue(queue):\n    return queue[:,:(K-N)]\n\n@torch.no_grad()\ndef enqueue(queue,k):\n    return torch.cat([k, queue],dim=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef concat_all_gather(tensor):\n    \n    tensors_gather = [torch.ones_like(tensor)\n        for _ in range(torch.distributed.get_world_size())]\n\n    output = torch.cat(tensors_gather, dim=1)\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    queue = torch.randn(N,K).cuda()\n    queue = nn.functional.normalize(queue, dim=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def saveModel(epoch, model,optimizer,loss,path):\n      torch.save({\n              'epoch': epoch,\n              'model_state_dict': model.state_dict(),\n              'optimizer_state_dict': optimizer.state_dict(),\n              'loss': loss\n              }, path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadModel(model,optimizer,path):\n    checkpoint = torch.load(path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    epoch = checkpoint['epoch']\n    loss = checkpoint['loss']\n\n    print('Epoch: ',epoch,'Loss: ',loss)\n    return model,optimizer, epoch, loss;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor e in range(20):\n    epoch_loss = 0.0\n    running_loss = 0.0\n    for i,(images) in enumerate(train_set):\n    \n        images = var(images.cuda())\n        optimizer.zero_grad()\n\n        images_q = images\n        images_k = images\n\n        q = encoder_q.forward(images_q)\n        q = nn.functional.normalize(q,dim=1)\n        \n        with torch.no_grad():\n            for p_k,p_q in zip(encoder_k.parameters(),encoder_q.parameters()):\n                val = (1-m)*p_q.data + m*p_k.data\n                p_k.data = p_k.data.copy_(val)\n                \n        \n            k = encoder_k.forward(images_k)\n            k = nn.functional.normalize(k, dim=1)\n\n\n\n         # positive logits: Nx1\n        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n        # negative logits: NxK\n        l_neg = torch.einsum('nc,ck->nk', [q, queue.clone().detach()])\n\n\n        logits = torch.cat([l_pos, l_neg], dim=1).cuda()\n\n        labels = torch.zeros(N).type(torch.cuda.LongTensor).cuda()\n\n        logits = logits/T;\n\n        loss = cec(logits, labels)\n\n        #updating query encoder\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n        running_loss += loss.item()\n\n        queue = dequeue(queue)\n        queue = enqueue(queue, k)\n        \n        if((i+1) % 50 == 0):\n            print('Epoch :',e+1,'Batch :',(i+1),'Loss :',float(running_loss/50))\n            running_loss = 0.0\n            saveModel(e,encoder_q,optimizer,epoch_loss,\"encoder_query.pth\")\n            saveModel(e,encoder_k,optimizer,epoch_loss,\"encoder_keys.pth\")\n        \n    saveModel(e,encoder_q,optimizer,epoch_loss,\"encoder_query.pth\")\n    saveModel(e,encoder_k,optimizer,epoch_loss,\"encoder_keys.pth\")\n    print('Epoch :',e+1, 'Loss :',epoch_loss/len(train_set))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}