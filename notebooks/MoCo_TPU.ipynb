{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoCo_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9kk2RUNv_iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd drive/My Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmFakq5QGt--",
        "colab_type": "text"
      },
      "source": [
        "## Setting Up Torch XLA \n",
        "For TPU Multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPJVqAKyml5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VERSION = \"20200516\"  #@param [\"1.5\" , \"20200516\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MazDUu-ojrvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd MoCo/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWnZP5Ph4svv",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzaetGN2jy6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import logging\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "from torch.autograd import Variable as var\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "\n",
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhJ1qJSFzN0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses_df = pd.DataFrame(columns=['Epoch', 'Loss', 'top1Accuracy','top5Accuracy'])\n",
        "logging.basicConfig(filename='./moco_tpu.log', filemode='w', format='%(levelname)s - %(message)s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhCyJXiu1vHZ",
        "colab_type": "text"
      },
      "source": [
        "## Save Model State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvjXHikSuZrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveModel(epoch, model, optimizer, loss, path):\n",
        "  torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': loss\n",
        "              }, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l37Tk_o11yIO",
        "colab_type": "text"
      },
      "source": [
        "## Load Model State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72pnhO3N1zyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadModel(model, path):\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "\n",
        "    print('Epoch: ',epoch,'Loss: ',loss)\n",
        "    return model, epoch, loss;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lti2smDS-AaH",
        "colab_type": "text"
      },
      "source": [
        "## Random Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTsygI2w9Hws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_augmentation():\n",
        "    return transforms.Compose([\n",
        "        # transforms.ToTensor(),\n",
        "        # transforms.Normalize((0.5,), (0.5,)), # for grayscale mnist to rgb\n",
        "        # transforms.ToPILImage(),\n",
        "        transforms.RandomResizedCrop(size=32,scale=(0.2, 1.)),\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomApply([transforms.Grayscale(PARAMETERS['num_channels'])],p=0.4),\n",
        "        transforms.ToTensor(),        \n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg6HyJNp_tcx",
        "colab_type": "text"
      },
      "source": [
        "# Defining the Hyper-parameters for moco_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eWzqwMiwV54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PARAMETERS = {}\n",
        "PARAMETERS['model_name'] = 'resnet18'\n",
        "PARAMETERS['model_saved'] = \"./saved_models/moco_saved_mnist.pth\"\n",
        "PARAMETERS['learning_rate'] = 0.03\n",
        "PARAMETERS['momentum'] = 0.9\n",
        "PARAMETERS['epochs'] = 100\n",
        "PARAMETERS['weight_decay'] = 0.0001\n",
        "PARAMETERS['batch_size'] = 128\n",
        "PARAMETERS['temperature'] = 0.07\n",
        "PARAMETERS['num_channels'] = 3\n",
        "PARAMETERS['dictionary_size'] = 4096\n",
        "PARAMETERS['num_workers'] = 4\n",
        "PARAMETERS['num_cores'] = 8\n",
        "PARAMETERS['log_steps'] = 20\n",
        "PARAMETERS['load_from_saved'] = False\n",
        "PARAMETERS['start_epoch'] = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmhhXlG-db98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "world_size = xm.xrt_world_size()\n",
        "rank = xm.get_ordinal()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPVuEn_oH-7E",
        "colab_type": "text"
      },
      "source": [
        "## Setting Up Process Group for Distributed Processing\n",
        "Note: PyTorch does not have any support for TPU as distributed backend.\n",
        "Using \"gloo\" here means we have to move the tensor to the CPU before performing a broadcast when shuffling later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GwamNit5YPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355'\n",
        "torch.distributed.init_process_group(\"gloo\", rank=rank, world_size=world_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLM1JTg14NTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = xm.xla_device()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwPdDq8Zvrkx",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bmN4bcPvuY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = get_random_augmentation()\n",
        "\n",
        "train_data = datasets.EMNIST(root='./data/', split='byclass', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "test_data = datasets.EMNIST(root='./data/', split='byclass', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "\n",
        "# train_data = datasets.MNIST(root='./data/', train=True,\n",
        "#                                         download=True, transform=transform)\n",
        "# test_data = datasets.MNIST(root='./data/', train=False,\n",
        "#                                        download=True, transform=transform)\n",
        "\n",
        "\n",
        "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    train_data,\n",
        "    num_replicas = xm.xrt_world_size(),\n",
        "    rank = xm.get_ordinal(),\n",
        "    shuffle = True)\n",
        "\n",
        "train_set = torch.utils.data.DataLoader(\n",
        "    train_data, \n",
        "    batch_size = PARAMETERS['batch_size'],\n",
        "    sampler = train_sampler,\n",
        "    num_workers = PARAMETERS['num_workers'], \n",
        "    pin_memory = True,drop_last=True)\n",
        "\n",
        "test_set = torch.utils.data.DataLoader(\n",
        "    test_data, \n",
        "    batch_size = PARAMETERS['batch_size'],\n",
        "    shuffle = False,\n",
        "    num_workers = PARAMETERS['num_workers'],\n",
        "    pin_memory = True,drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS2vU71G-gcr",
        "colab_type": "text"
      },
      "source": [
        "# Model Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CquiAVXIJjXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = PARAMETERS['batch_size']\n",
        "LR = PARAMETERS['learning_rate'] * xm.xrt_world_size()\n",
        "T = PARAMETERS['temperature']\n",
        "C = PARAMETERS['num_channels']\n",
        "K = PARAMETERS['dictionary_size']\n",
        "m = PARAMETERS['momentum']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1P2A7YKXyb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def gather_tensors_from_tpu(tensor):\n",
        "  \n",
        "  tensors_gather = [torch.ones_like(tensor)\n",
        "        for _ in range(torch.distributed.get_world_size())]\n",
        "  #tensors_gather = xm.all_gather(tensor,dim=0)\n",
        "\n",
        "  return torch.cat(tensors_gather,dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BHRrGXZ-kvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderModel(nn.Module):\n",
        "    def __init__(self, base_model_name, channels_out):\n",
        "        super(EncoderModel, self).__init__()\n",
        "\n",
        "        if base_model_name == 'resnet50':\n",
        "          model = models.resnet50(pretrained=False)\n",
        "        elif base_model_name == 'resnet18':\n",
        "          model = models.resnet18(pretrained=False)\n",
        "        \n",
        "        penultimate = model.fc.weight.shape[1]\n",
        "        modules = list(model.children())[:-1]\n",
        "        self.encoder = nn.Sequential(*modules)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(penultimate, channels_out);\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtBpTmWritQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoCoModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MoCoModel, self).__init__()\n",
        "\n",
        "    self.query_enc = EncoderModel(PARAMETERS['model_name'],N)\n",
        "    self.key_enc = EncoderModel(PARAMETERS['model_name'],N)\n",
        "\n",
        "    for param_q, param_k in zip(self.query_enc.parameters(), self.key_enc.parameters()):\n",
        "      param_k.data.copy_(param_q.data)\n",
        "      param_k.requires_grad = False  # not update by gradient\n",
        "\n",
        "    self.register_buffer(\"queue\", torch.randn(N, K))\n",
        "    self.queue = nn.functional.normalize(self.queue, dim=0)\n",
        "\n",
        "    self.register_buffer(\"queue_index\", torch.zeros(1, dtype=torch.long))\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def update_key_params(self):\n",
        "    for p_k,p_q in zip(self.key_enc.parameters(),self.query_enc.parameters()):\n",
        "        val = (1-m)*p_q.data + m*p_k.data\n",
        "        p_k.data = p_k.data.copy_(val)\n",
        "    \n",
        "  @torch.no_grad()\n",
        "  def update_queue(self, keys):\n",
        "      keys = gather_tensors_from_tpu(keys)\n",
        "\n",
        "      index = int(self.queue_index)\n",
        "\n",
        "      self.queue[:, index:index + N] = keys.T\n",
        "      index = (index + N) % K\n",
        "\n",
        "      self.queue_index[0] = index\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def shuffle(self, x):\n",
        "\n",
        "      current_batch_size = x.shape[0]\n",
        "      x_gather = gather_tensors_from_tpu(x)\n",
        "      gathered_batch_size = x_gather.shape[0]\n",
        "\n",
        "      num_tpus = gathered_batch_size // current_batch_size\n",
        "\n",
        "      shuffle_index = torch.randperm(gathered_batch_size).cpu()\n",
        "\n",
        "      torch.distributed.broadcast(shuffle_index, src=0)\n",
        "\n",
        "      unshuffle_index = torch.argsort(shuffle_index)\n",
        "\n",
        "      current_tpu = xm.get_ordinal()\n",
        "      current = shuffle_index.view(num_tpus, -1)[current_tpu]\n",
        "\n",
        "      return x_gather[current], unshuffle_index\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def unshuffle(self, x, unshuffle_index):\n",
        "\n",
        "      current_batch_size = x.shape[0]\n",
        "      x_gather = gather_tensors_from_tpu(x)\n",
        "      gathered_batch_size = x_gather.shape[0]\n",
        "\n",
        "      num_tpus = gathered_batch_size // current_batch_size\n",
        "\n",
        "      current_tpu = xm.get_ordinal()\n",
        "      current = unshuffle_index.view(num_tpus, -1)[current_tpu]\n",
        "\n",
        "      return x_gather[current]\n",
        "\n",
        "  def forward(self, images):\n",
        "      q = self.query_enc(images)\n",
        "      q = nn.functional.normalize(q,dim=1)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        images, unshuffle_index = self.shuffle(images)\n",
        "\n",
        "        self.update_key_params()\n",
        "\n",
        "        k = self.key_enc.forward(images)\n",
        "        k = nn.functional.normalize(k, dim=1)\n",
        "        k = self.unshuffle(k, unshuffle_index)\n",
        "\n",
        "      l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
        "\n",
        "      l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
        "\n",
        "\n",
        "      logits = torch.cat([l_pos, l_neg], dim=1)\n",
        "\n",
        "      labels = torch.zeros(N).type(torch.LongTensor)\n",
        "\n",
        "      logits = logits/T;\n",
        "\n",
        "      self.update_queue(k)\n",
        "\n",
        "      return logits,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCdrpY_U6qVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5BYjOSSAyXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EpochAccuracy(object):\n",
        "\n",
        "  def __init__(self, acc_type):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "    self.acc_type = acc_type\n",
        "\n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val * n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count\n",
        "\n",
        "  def __get__(self):\n",
        "    return self.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj6CTooWAKVc",
        "colab_type": "text"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TildqC4pbvjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model():\n",
        "\n",
        "  model = MoCoModel()\n",
        "  model = torch.nn.parallel.DistributedDataParallel(model)\n",
        "\n",
        "  # Wrapping to Xla XMP Wrapper\n",
        "  WRAPPED_MODEL = xmp.MpModelWrapper(model)\n",
        "\n",
        "  if (PARAMETERS['load_from_saved']):\n",
        "      moco_model = MoCoModel()\n",
        "      moco_model, PARAMETERS['start_epoch'], loss = loadModel(moco_model, PARAMETERS['model_saved'])\n",
        "      PARAMETERS['start_epoch'] += 2\n",
        "      PARAMETERS['load_from_saved'] = False\n",
        "      print(\"Loaded model loss\", loss)\n",
        "      WRAPPED_MODEL = xmp.MpModelWrapper(moco_model)\n",
        "\n",
        "  # Only instantiate model weights once in memory.\n",
        "  moco_model = WRAPPED_MODEL.to(device)\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(moco_model.parameters(), lr=LR, momentum=0.9, weight_decay=PARAMETERS['weight_decay'])\n",
        "\n",
        "  def training_loop(data):\n",
        "    epoch_loss = 0.0\n",
        "    running_loss = 0.0\n",
        "    tracker = xm.RateTracker()\n",
        "    moco_model.train()\n",
        "\n",
        "    for i, (images, _) in enumerate(data):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      logits, labels = moco_model.forward(images)\n",
        "\n",
        "      loss = loss_function(logits, labels)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      xm.optimizer_step(optimizer)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      tracker.add(PARAMETERS['batch_size'])\n",
        "      if((i+1) % 5 == 0):\n",
        "        print('[xla:{}]({}) Loss={:.5f} Rate={:.2f} GlobalRate={:.2f} Time={}'.format(\n",
        "              xm.get_ordinal(), i, running_loss/5, tracker.rate(),\n",
        "              tracker.global_rate(), time.asctime()), flush=True)\n",
        "        running_loss = 0.0\n",
        "      \n",
        "    return epoch_loss, running_loss\n",
        "    \n",
        "  def testing_loop(data):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    validation_loss = 0\n",
        "    top1_acc = EpochAccuracy('top1')\n",
        "    top5_acc = EpochAccuracy('top5')\n",
        "    moco_model.eval()\n",
        "    images, labels, pred = None, None, None\n",
        "    with torch.no_grad():\n",
        "      for images, _ in data:\n",
        "        logits, labels = moco_model.forward(images)\n",
        "\n",
        "        loss_v = loss_function(logits,labels)\n",
        "        validation_loss += loss_v.item()\n",
        "\n",
        "        batch_acc1, batch_acc5 = accuracy(logits,labels,topk=(1,5))\n",
        "\n",
        "        top1_acc.update(batch_acc1[0].item(),images[0].size(0))\n",
        "        top5_acc.update(batch_acc5[0].item(),images[0].size(0))\n",
        "  \n",
        "    epoch_acc = (top1_acc.__get__(),top5_acc.__get__())\n",
        "    return epoch_acc, validation_loss/len(data)\n",
        "    \n",
        "\n",
        "  acc = 0.0\n",
        "  data, pred, target = None, None, None\n",
        "\n",
        "  for epoch in range(PARAMETERS['start_epoch'], PARAMETERS['epochs'] + 1):\n",
        "    para_loader = pl.ParallelLoader(train_set, [device],fixed_batch_size=True)\n",
        "    epoch_loss, running_loss = training_loop(para_loader.per_device_loader(device))\n",
        "\n",
        "    xm.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': moco_model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': (epoch_loss/len(train_set))\n",
        "              }, PARAMETERS['model_saved'])\n",
        "    \n",
        "    train_loss = epoch_loss/len(train_set)\n",
        "    para_loader = pl.ParallelLoader(test_set, [device],fixed_batch_size=True)\n",
        "    acc, validation_loss = testing_loop(para_loader.per_device_loader(device))\n",
        "    xm.master_print(\"[\"+str(epoch)+\" , \"+str(train_loss)+\" , : \"+str(acc[0])+\" , \"+str(acc[1])+\" , \"+str(validation_loss)+\"]\")\n",
        "\n",
        "    #logging.INFO('Epoch: ', epoch + 1, 'Loss: ', (epoch_loss/len(train_set)),'Top1Accuracy: ',acc[0],'%', ' Top5Accuracy: ',acc[1],'%', 'Validation Loss ', validation_loss)\n",
        "    losses_df.append({'Epoch': epoch, 'Loss': float(epoch_loss/len(train_set)), 'top1Accuracy': acc[0], 'top5Accuracy': acc[1]}, ignore_index=True)\n",
        "\n",
        "  return acc, data, pred, target, moco_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWYn1w1rcXHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def start_training(rank, parameters):\n",
        "  global PARAMETERS\n",
        "  PARAMETERS = parameters\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  acc, data, pred, target, model = train_model()\n",
        "  print('Top1-Accuracy: ',acc[0],'%', ' Top5-Accuracy: ',acc[1],'%')\n",
        "\n",
        "losses_df.to_csv(r'./moco_train_tpu.csv', encoding='utf-8', index=False)\n",
        "PARAMETERS['load_from_saved'] = False\n",
        "# xmp.spawn(start_training, args=(PARAMETERS, ), nprocs = PARAMETERS['num_cores'],\n",
        "#           start_method='fork')\n",
        "xmp.spawn(start_training, args=(PARAMETERS, ), nprocs = world_size,\n",
        "          start_method='fork')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}